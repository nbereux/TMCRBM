{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from rbm.definitions import DATASET_DIR, OUTPUT_DIR\n",
    "from rbm.models import TMCRBM2D\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a TMC-RBM on the 2d3c artificial dataset using the TMC2D algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(np.genfromtxt(DATASET_DIR.joinpath('data_2d_3c_balanced_seed12.d')).T, dtype=dtype, device=device)\n",
    "# The data is binary with values in {-1, 1}, so we scale it to be in {0, 1}\n",
    "data = (data+1)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines all the parameters necessary to initialize the TMC-RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "lr = 0.2\n",
    "# Number of MCMC iterations\n",
    "NGibbs = 20\n",
    "# Mini-batch size\n",
    "mb_s = 2000\n",
    "# Number of hidden units \n",
    "Nh = 50 \n",
    "# Number of visible units\n",
    "Nv = data.shape[0]\n",
    "# steps used for the temporal mean\n",
    "it_mean = 15\n",
    "# constraint on the gaussian bath\n",
    "N = 20000\n",
    "# nb of chains for each constraint point\n",
    "nb_chain = 50\n",
    "# nb of constraint point on each dimension\n",
    "nb_point_dim = torch.tensor([30,30])\n",
    "# if True uses PCA for the projection else uses the SVD of the weight matrix\n",
    "PCA = True\n",
    "# index of the direction you want to put the constraints on (careful : first direction is 0, second is 1 etc...)\n",
    "direction = torch.tensor([0, 1], device = device)\n",
    "# the distance added to the extremas of the data projection for the discretization\n",
    "border_length = 0.2\n",
    "# permanent chain\n",
    "ResetChain = False\n",
    "# Wether to use Centered gradient update or not\n",
    "UpdCentered = True\n",
    "# Number of persistent Markov chains for the PCD algorithm. Not useful in this notebook but should be initialized if \n",
    "# one wants to use the PCD method alongside the TMC\n",
    "num_pcd = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialize the model using all the previous parameters\n",
    "RBM_TMC = TMCRBM2D(num_visible=Nv,\n",
    "               num_hidden=Nh,\n",
    "               device=device,\n",
    "               lr=lr,\n",
    "               gibbs_steps=NGibbs,\n",
    "               UpdCentered=True,\n",
    "               CDLearning=True,\n",
    "               mb_s=mb_s,\n",
    "               num_pcd=num_pcd,\n",
    "               N = N,\n",
    "               nb_chain = nb_chain,\n",
    "               nb_point_dim=nb_point_dim,\n",
    "               direction=direction,\n",
    "               PCA = PCA,\n",
    "               border_length = border_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "ep_max = 1020\n",
    "\n",
    "# All saved filenames will have this stamp \n",
    "RBM_TMC.file_stamp = 'Demo2d3cB'\n",
    "\n",
    "# We define here the timesteps where we will save the RBM during training\n",
    "fq_msr_RBM = 20\n",
    "base = 1.7\n",
    "v = np.array([0,1],dtype=int)\n",
    "allm = np.append(np.array(0),base**np.array(list(range(30))))\n",
    "for k in range(30):\n",
    "    for m in allm:\n",
    "        v = np.append(v,int(base**k)+int(m)) \n",
    "v = np.array(list(set(v)))\n",
    "v = np.sort(v)\n",
    "RBM_TMC.list_save_time = v\n",
    "RBM_TMC.list_save_rbm = np.arange(1, ep_max, fq_msr_RBM)\n",
    "\n",
    "# Visible bias initialisation\n",
    "RBM_TMC.SetVisBias(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbereux/rbm/rbm/models/tmcrbm2d.py:421: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  self.w_hat_b = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving nb_upd=0\n",
      "Saving nb_upd=1\n",
      "Saving nb_upd=2\n",
      "Saving nb_upd=3\n",
      "Saving nb_upd=4\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33960/1302182158.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "  cont1 = plt.contour(RBM_TMC.w_hat_tmp[0], RBM_TMC.w_hat_tmp[1], np.log(RBM_TMC.p_m.cpu().numpy()), 50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT  1\n",
      "Saving nb_upd=5\n",
      "Saving nb_upd=6\n",
      "Saving nb_upd=8\n",
      "Saving nb_upd=9\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  2\n",
      "Saving nb_upd=10\n",
      "Saving nb_upd=12\n",
      "Saving nb_upd=14\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  3\n",
      "Saving nb_upd=15\n",
      "Saving nb_upd=16\n",
      "Saving nb_upd=18\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  4\n",
      "Saving nb_upd=22\n",
      "Saving nb_upd=24\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  5\n",
      "Saving nb_upd=25\n",
      "Saving nb_upd=26\n",
      "Saving nb_upd=28\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  6\n",
      "Saving nb_upd=32\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  7\n",
      "Saving nb_upd=38\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  8\n",
      "Saving nb_upd=41\n",
      "Saving nb_upd=42\n",
      "Saving nb_upd=43\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  9\n",
      "Saving nb_upd=45\n",
      "Saving nb_upd=48\n",
      "Saving nb_upd=49\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  10\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  11\n",
      "Saving nb_upd=55\n",
      "model updates saved at /home/nbereux/rbm/model/AllParametersDemo2d3cB.h5\n",
      "model saved at /home/nbereux/rbm/model/RBMDemo2d3cB.h5\n",
      "IT  12\n"
     ]
    }
   ],
   "source": [
    "# Epoch frequency on which to generate figures in the output folders\n",
    "# Useful to monitor the learning\n",
    "fq_fig = 20\n",
    "\n",
    "if RBM_TMC.PCA:\n",
    "    _, _, V = torch.svd(data.T)\n",
    "    proj_data = torch.mm(data.T,V).cpu()/ (RBM_TMC.Nv**0.5)\n",
    "\n",
    "\n",
    "for t in range(ep_max):\n",
    "    RBM_TMC.fit(data,ep_max=1)\n",
    "    \n",
    "    if t%fq_fig == 0:\n",
    "        if not(RBM_TMC.PCA):\n",
    "            _,_,V = torch.svd(RBM_TMC.W)\n",
    "            proj_data = torch.mm(data.T,V).cpu()/ (RBM_TMC.Nv**0.5)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        plt.scatter(proj_data[:, RBM_TMC.direction[0]], proj_data[:,RBM_TMC.direction[1]], label = \"dataset\")\n",
    "        cont1 = plt.contour(RBM_TMC.w_hat_tmp[0], RBM_TMC.w_hat_tmp[1], np.log(RBM_TMC.p_m.cpu().numpy()), 50)\n",
    "        plt.title(\"RBM Potential\")\n",
    "        plt.colorbar(cont1)\n",
    "        plt.legend()\n",
    "        plt.savefig(OUTPUT_DIR.joinpath(f\"{RBM_TMC.file_stamp}_fig_pot_{t}.png\"))\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        plt.scatter(proj_data[:, RBM_TMC.direction[0]], proj_data[:,RBM_TMC.direction[1]], label = \"dataset\")\n",
    "        cont2 = plt.contour(RBM_TMC.w_hat_tmp[0], RBM_TMC.w_hat_tmp[1], RBM_TMC.p_m.cpu().numpy(), 50)\n",
    "        plt.title('RBM Probability')\n",
    "        plt.legend()\n",
    "        plt.colorbar(cont2)\n",
    "        plt.savefig(OUTPUT_DIR.joinpath(f\"{RBM_TMC.file_stamp}_fig_proba_{t}.png\"))\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f87c0831f9dd78408486b35ff19bc1f88be2dc350939ee20e3cdfd9bb0df7070"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
